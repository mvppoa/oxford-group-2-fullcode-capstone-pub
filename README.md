# AI Crew for professional networks blog posting
## Introduction
This project leverages the CrewAI framework to automate professional content creation for network platforms. It orchestrates a team of autonomous AI agents that work together to create comprehensive blog posts by gathering and formatting data from online sources.

- [CrewAI Framework](#crewai-framework)
- [Running the script](#running-the-script)
- [Details & Explanation](#details--explanation)
- [Agents & tasks](#agents--tasks)
- [Inputs](#inputs)
- [Agents](#agents)
- [Further considerations](#further-considerations)
- [License](#license)

## CrewAI Framework
CrewAI is designed to facilitate the collaboration of role-playing AI agents. In this example, these agents work together to analyze company culture and identify role requirements to create comprehensive job postings and industry analysis.

## Running the Script
It uses GPT-4o by default so you should have access to that to run it.

***Disclaimer:** This will use gpt-4o unless you change it to use a different model, and by doing so it may incur in different costs.*

- **Configure Environment**: Set up `.env` with the environment variables for [OpenAI](https://platform.openai.com/api-keys) and other tools as needed, like [Serper](serper.dev).
- **Install Dependencies**: Run `poetry lock && poetry install`.
- **Customize**: Modify `src/blog_posting/main.py` to add custom inputs for your agents and tasks.
- **Customize Further**: Check `src/blog_posting/config/agents.yaml` to update your agents and `src/blog_posting/config/tasks.yaml` to update your tasks.
- **Execute the Script**: Run `poetry run blog_posting` and input your project details.

## Details & Explanation
- **Running the Script**: Execute `poetry run blog_posting`. The script will leverage the CrewAI framework to generate a detailed job posting.
- **Key Components**:
  - `src/blog_posting/main.py`: Main script file.
  - `src/blog_posting/crew.py`: Main crew file where agents and tasks come together, and the main logic is executed.
  - `src/blog_posting/config/agents.yaml`: Configuration file for defining agents.
  - `src/blog_posting/config/tasks.yaml`: Configuration file for defining tasks.
  - `src/blog_posting/tools`: Contains tool classes used by the agents.

## Agents & tasks
The goal is to generate text and visual content that can be posted to a professional network platform by searching and formatting data gathered online. It would link a target company's strategy for one of their products to news related to that area, generate a summary of both, then create an image reflecting the contents, ready to be posted online.

### Inputs
Inputs can be found in the `main.py` file.

The main logical inputs are:
- `company` : The name of the targeted company e.g. Rolls-Royce
- `product` : The particular product that the strategy search will look for e.g. small modular reactor
- `audience` : The targetted audience of the blog post
- `news_search_terms` : The scope of the news search that will make up the second part of the post e.g. nuclear energy

Additional parameters:
- `articles` : The number of news articles to be looked up and summarized in the news search part of the post
- `product_summary_paragraphs` : The number of paragraphs to generate in the strategy part of the blog
- `article_summary_paragraphs` : The number of paragraphs to generate in the news search part of the blog
- `percentage_strategy` : The percentage of strategic information to be included in the summary of the company's product

### Agents
1. **Strategist** : Identifies the company's strategy for the targeted product and present a summary
2. **Newsfeed agent** : Runs online searches (via duckduckgo) for the specified search terms and identify the specified number of relevant articles
3. **Blog writer**: Produces a digest the outputs of both previous agents based on the provided parameters e.g. number of paragraphs for each section. This agent will request human review (HITL).
4. **Sketcher**: Creates an image relevant to the contents generated by blog writer, to be used as a headline. It will also request feedback.

### Further considerations
The original goal of the exercise was to create a blog post and publish it directly to LinkedIn using an AI agent. However, since publishing would have required a LinkedIn API key, we decided instead to generate the blog content and manually post it ourselves. While the final step of the exercise was intended to include an agent that would handle pagination for the blog article, we ran out of OpenAI credits before completing this part and were unable to present further results. Throughout the process, we also observed that agent communication is crucial to maintaining contextâ€”without proper chaining of requests, context can be lost between agents.

## License
This project is released under the MIT License.
